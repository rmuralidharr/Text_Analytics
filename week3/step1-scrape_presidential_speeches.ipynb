{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step1: Scraping Presidential Speeches\n",
    "\n",
    "The Miller Center maintains an archive of all presidential speeches. The archive is available at https://millercenter.org/the-presidency/presidential-speeches. The archive contains speeches from all presidents from George Washington to Donald Trump. Each speech has a name of the president, title, date, a brief abstract about the speech, and transcript. Some speeches also have a video. \n",
    "\n",
    "The archive is a great resource for anyone interested in the history of the United States."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.firefox.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from webdriver_manager.firefox import GeckoDriverManager \n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "\n",
    "import re\n",
    "import dateparser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape Links to Speechs from the Miller Center\n",
    "\n",
    "The first thing we need to do is scrape links to all the presidential speeches. The main page uses JavaScript and will only reveal links as you scroll down the page. This, therefore, will require us to use Selenium to scrape this page; as selenium is our only option for scraping JavaScript pages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start a driver session....\n",
    "\n",
    "    # if you have selenium 3 installed, use one of these:\n",
    "#driver = webdriver.Firefox(executable_path=GeckoDriverManager().install()) # this will work on Windows and Mac, and should work on Linux when run the first time\n",
    "#driver = webdriver.Firefox(executable_path=<insert path to manual downloaded geckodriver>)\n",
    "#driver = webdriver.Firefox() # use if geckodriver is in your PATH environmnet variable (which includes the same folder as your notebook)\n",
    "\n",
    "    # if you hve selenium 4 installed, use one of these:\n",
    "#driver = webdriver.Firefox(service=Service(GeckoDriverManager().install())) # this will work on Windows and Mac, and should work on Linux when run the first time\n",
    "driver = webdriver.Firefox() # use if geckodriver is in your PATH environmnet variable (which includes the same folder as your notebook)\n",
    "\n",
    "# load page with Selenium\n",
    "driver.get(\"https://millercenter.org/the-presidency/presidential-speeches\")\n",
    "driver.implicitly_wait(10) # implicitly_wait method sets a sticky timeout to implicitly wait for an element to be found, or a command to complete. This method only \n",
    "# needs to be called one time per session. \n",
    "\n",
    "pause_scroll = 3 # we need to pause after each time we scroll down\n",
    "previous_page_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "while True:\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(pause_scroll)\n",
    "    new_page_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "    if new_page_height == previous_page_height:\n",
    "        break\n",
    "    previous_page_height = new_page_height\n",
    "    \n",
    "\n",
    "page_source = driver.page_source\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#retrieve urls to all speeches\n",
    "bsobject_linkpage = bs(page_source,'lxml')\n",
    "bs_links = bsobject_linkpage.find_all(\"a\", href = re.compile('presidential-speeches/'))\n",
    "bs_links[-1] # display the first 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_link_list = []\n",
    "for link in bs_links:   \n",
    "    speech_link_list.append(link['href'])\n",
    "\n",
    "speech_link_list[:5] # display first 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For each URL, scrape the speech\n",
    "\n",
    "For each of the links that we extracted from the main page, we will load the page, and use beautiful soup to extract the speech text, title, date, about text, and president name.\n",
    "\n",
    "NOTE: This will take a long time to run -- possible an hour or more (the Miller Center has a lot of speeches!) Also, you may notice that we pause between pages - this is to make sure we are not hitting the server too hard. Some systems will notice this and reject your requests if you are requesting pages too fast from one IP address."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking at html content...\n",
    "# there is a class called president-name, episode-date, speed-loc, about-sidebar--intro, \n",
    "# presidential-speeches--title, presidential-speeches--title, view-transcript \n",
    "# \n",
    "# view-transcript content may have multiple \"Transcript\" Headers (header 3)\n",
    "# it will also include a title ending in a colon\n",
    "# \n",
    "#scrape the speech#\n",
    "\n",
    "driver = webdriver.Firefox() # start a new session\n",
    "\n",
    "pause_between_pages = 2\n",
    "\n",
    "# create empty lists to store data from each page\n",
    "title, speech, name, date, about = ([] for i in range(5))\n",
    "\n",
    "for link in speech_link_list:\n",
    "    #access speech page with Selenium and find div class \"transcript-inner\"\n",
    "    driver.get(link)\n",
    "\n",
    "    # use beautiful soup to parse the html\n",
    "    bsobject_speechpage = bs(driver.page_source, 'lxml')\n",
    "\n",
    "    #scrape speech test, tital, presidents name, date of speech and text about the speech.\n",
    "    try:\n",
    "        title.append(bsobject_speechpage.find('h2', class_=\"presidential-speeches--title\").text.strip())\n",
    "    except:\n",
    "        title.append(\"No title available\")\n",
    "        \n",
    "    try:\n",
    "        speech_raw = bsobject_speechpage.find('div', class_=\"transcript-inner\").text.strip().replace('\\xa0', '')\n",
    "        speech.append(re.sub(r\"Transcript|\\n\",\"\",speech_raw)) \n",
    "    except:\n",
    "        try: # older links use the class view-transcript instead of transcript-inner; if transcript-inner doesn't work, thy view-transcript\n",
    "            speech_raw = bsobject_speechpage.find('div', class_=\"view-transcript\").text.strip().replace('\\xa0', '')\n",
    "            speech.append(re.sub(r\"Transcript|\\n\",\" \",speech_raw)) \n",
    "        except:\n",
    "            speech.append(\"No speech available\")\n",
    "    \n",
    "    try:\n",
    "        name.append(bsobject_speechpage.find('p', class_=\"president-name\").text.strip())\n",
    "    except:\n",
    "        name.append(\"No name available\")\n",
    "    \n",
    "    try:\n",
    "        date.append(dateparser.parse(bsobject_speechpage.find('p', class_=\"episode-date\").text.strip()))\n",
    "    except:\n",
    "        date.append(\"No date available\")\n",
    "        \n",
    "    try:\n",
    "        about.append(bsobject_speechpage.find('div', class_=\"about-sidebar--intro\").text.strip())\n",
    "    except:\n",
    "        about.append(\"No info available\")\n",
    "    \n",
    "    # pause before getting next page\n",
    "    time.sleep(pause_between_pages)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create dataframe and save to csv\n",
    "\n",
    "Finally, we assemble all out data into a dataframe and save it to a csv file. We will use this csv file in out next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save this to a dataframe and save to a csv file#\n",
    "if len(title) == len(speech) == len(name) == len(date) == len(about):\n",
    "    speeches_presidents = pd.DataFrame({'name':name,'title':title,'date':date,'about':about,'speech':speech})\n",
    "    speeches_presidents['speech'] = speeches_presidents['speech'].apply(lambda x: x.replace(\".\",\". \"))\n",
    "    speeches_presidents.to_csv(\"./data/presidential_speeches.csv\",index=False)\n",
    "else:\n",
    "    print(\"Something went wrong with scraping the speeches. Please check the code.\")\n",
    "    \n",
    "    # dump the data to csv files for debugging\n",
    "    df_names = pd.DataFrame({'name':name}) \n",
    "    df_names.to_csv(\"./data/names.csv\",index=False)\n",
    "    \n",
    "    df_titles = pd.DataFrame({'title':title})\n",
    "    df_titles.to_csv(\"./data/titles.csv\",index=False)\n",
    "    \n",
    "    df_dates = pd.DataFrame({'date':date})\n",
    "    df_dates.to_csv(\"./data/dates.csv\",index=False)\n",
    "    \n",
    "    df_infos = pd.DataFrame({'about':about})\n",
    "    df_infos.to_csv(\"./data/about.csv\",index=False)\n",
    "    \n",
    "    df_speeches = pd.DataFrame({'speech':speech})\n",
    "    df_speeches.to_csv(\"./data/speeches.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
