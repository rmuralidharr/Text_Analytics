{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Airline Tweets: Sentiment Analysis & Simple Classification\n",
    "\n",
    "### ISM6564\n",
    "\n",
    "**Week05\n",
    "\n",
    "&copy; 2023 Dr. Tim Smith\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this notebook we will analysze the sentiment from a dataset on how travelers tweeted about their airline-related feelings, scraped from Twitter in February 2015;."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# import tools to pre-process the text data\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Extracting features from text files\n",
    "#   SciKit Learn includes a number of useful feature extraction classes \n",
    "#   https://scikit-learn.org/stable/modules/classes.html#module-sklearn.feature_extraction.text\n",
    "# \n",
    "#   We will use TfidfVectorizer (which includes pre-processing, tokenization, and filtering out stop words)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# import tools to reduce the dimensionality of the data\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "# import tools to split the data into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# import ML classifiers we will use to model the data\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# import tools to evaluate the model performance\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dsata Load and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "\n",
       "               tweet_created tweet_location               user_timezone  \n",
       "0  2015-02-24 11:35:52 -0800            NaN  Eastern Time (US & Canada)  \n",
       "1  2015-02-24 11:15:59 -0800            NaN  Pacific Time (US & Canada)  \n",
       "2  2015-02-24 11:15:48 -0800      Lets Play  Central Time (US & Canada)  \n",
       "3  2015-02-24 11:15:36 -0800            NaN  Pacific Time (US & Canada)  \n",
       "4  2015-02-24 11:14:45 -0800            NaN  Pacific Time (US & Canada)  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in the data \n",
    "df = pd.read_csv('./data/TweetsWtSentiment.csv') \n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TweetTokenizer()\n",
    "\n",
    "def clear_text(text):\n",
    "    # tokenize the text\n",
    "    # nltk.download('punkt') # uncomment if you need to download the punkt package\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    \n",
    "    # remove all tokens that are not alphabetic\n",
    "    tokens = [word for word in tokens if word.isalpha()]\n",
    "    \n",
    "    # make lowercase\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "\n",
    "    # remove all tokens that are only one character\n",
    "    tokens = [word for word in tokens if len(word) > 1]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['clean_text']=df.text.apply(lambda x: clear_text(x))   \n",
    "df['hashtags'] = df.text.apply(lambda text: re.findall(r\"#(\\w+)\", text))\n",
    "df['handles'] = df.text.apply(lambda text: re.findall(r\"@(\\w+)\", text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_sentiment_confidence</th>\n",
       "      <th>negativereason</th>\n",
       "      <th>negativereason_confidence</th>\n",
       "      <th>airline</th>\n",
       "      <th>airline_sentiment_gold</th>\n",
       "      <th>name</th>\n",
       "      <th>negativereason_gold</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>tweet_coord</th>\n",
       "      <th>tweet_created</th>\n",
       "      <th>tweet_location</th>\n",
       "      <th>user_timezone</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>handles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>570306133677760513</td>\n",
       "      <td>neutral</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cairdin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica What @dhepburn said.</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:35:52 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>what said</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica, dhepburn]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>570301130888122368</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.3486</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:59 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>plus added commercials to the experience tacky</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>570301083672813571</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6837</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yvonnalynn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:48 -0800</td>\n",
       "      <td>Lets Play</td>\n",
       "      <td>Central Time (US &amp; Canada)</td>\n",
       "      <td>today must mean need to take another trip</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>570301031407624196</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Bad Flight</td>\n",
       "      <td>0.7033</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:15:36 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>really aggressive to blast obnoxious entertain...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>570300817074462722</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:45 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>and really big bad thing about it</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>570300767074181121</td>\n",
       "      <td>negative</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>Can't Tell</td>\n",
       "      <td>0.6842</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>jnardino</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica seriously would pay $30 a fligh...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:14:33 -0800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>seriously would pay flight for seats that have...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>570300616901320704</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6745</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cjmcginnis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica yes, nearly every time I fly VX...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:13:57 -0800</td>\n",
       "      <td>San Francisco CA</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>yes nearly every time fly vx this ear worm won...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>570300248553349120</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pilot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica Really missed a prime opportuni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:12:29 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>really missed prime opportunity for men withou...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>570299953286942721</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.6559</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dhepburn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@virginamerica Well, I didn't…but NOW I DO! :-D</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 11:11:19 -0800</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>Pacific Time (US &amp; Canada)</td>\n",
       "      <td>well but now do</td>\n",
       "      <td>[]</td>\n",
       "      <td>[virginamerica]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>570295459631263746</td>\n",
       "      <td>positive</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Virgin America</td>\n",
       "      <td>NaN</td>\n",
       "      <td>YupitsTate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>@VirginAmerica it was amazing, and arrived an ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-24 10:53:27 -0800</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>Eastern Time (US &amp; Canada)</td>\n",
       "      <td>it was amazing and arrived an hour early too g...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[VirginAmerica]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             tweet_id airline_sentiment  airline_sentiment_confidence  \\\n",
       "0  570306133677760513           neutral                        1.0000   \n",
       "1  570301130888122368          positive                        0.3486   \n",
       "2  570301083672813571           neutral                        0.6837   \n",
       "3  570301031407624196          negative                        1.0000   \n",
       "4  570300817074462722          negative                        1.0000   \n",
       "5  570300767074181121          negative                        1.0000   \n",
       "6  570300616901320704          positive                        0.6745   \n",
       "7  570300248553349120           neutral                        0.6340   \n",
       "8  570299953286942721          positive                        0.6559   \n",
       "9  570295459631263746          positive                        1.0000   \n",
       "\n",
       "  negativereason  negativereason_confidence         airline  \\\n",
       "0            NaN                        NaN  Virgin America   \n",
       "1            NaN                     0.0000  Virgin America   \n",
       "2            NaN                        NaN  Virgin America   \n",
       "3     Bad Flight                     0.7033  Virgin America   \n",
       "4     Can't Tell                     1.0000  Virgin America   \n",
       "5     Can't Tell                     0.6842  Virgin America   \n",
       "6            NaN                     0.0000  Virgin America   \n",
       "7            NaN                        NaN  Virgin America   \n",
       "8            NaN                        NaN  Virgin America   \n",
       "9            NaN                        NaN  Virgin America   \n",
       "\n",
       "  airline_sentiment_gold        name negativereason_gold  retweet_count  \\\n",
       "0                    NaN     cairdin                 NaN              0   \n",
       "1                    NaN    jnardino                 NaN              0   \n",
       "2                    NaN  yvonnalynn                 NaN              0   \n",
       "3                    NaN    jnardino                 NaN              0   \n",
       "4                    NaN    jnardino                 NaN              0   \n",
       "5                    NaN    jnardino                 NaN              0   \n",
       "6                    NaN  cjmcginnis                 NaN              0   \n",
       "7                    NaN       pilot                 NaN              0   \n",
       "8                    NaN    dhepburn                 NaN              0   \n",
       "9                    NaN  YupitsTate                 NaN              0   \n",
       "\n",
       "                                                text tweet_coord  \\\n",
       "0                @VirginAmerica What @dhepburn said.         NaN   \n",
       "1  @VirginAmerica plus you've added commercials t...         NaN   \n",
       "2  @VirginAmerica I didn't today... Must mean I n...         NaN   \n",
       "3  @VirginAmerica it's really aggressive to blast...         NaN   \n",
       "4  @VirginAmerica and it's a really big bad thing...         NaN   \n",
       "5  @VirginAmerica seriously would pay $30 a fligh...         NaN   \n",
       "6  @VirginAmerica yes, nearly every time I fly VX...         NaN   \n",
       "7  @VirginAmerica Really missed a prime opportuni...         NaN   \n",
       "8    @virginamerica Well, I didn't…but NOW I DO! :-D         NaN   \n",
       "9  @VirginAmerica it was amazing, and arrived an ...         NaN   \n",
       "\n",
       "               tweet_created    tweet_location               user_timezone  \\\n",
       "0  2015-02-24 11:35:52 -0800               NaN  Eastern Time (US & Canada)   \n",
       "1  2015-02-24 11:15:59 -0800               NaN  Pacific Time (US & Canada)   \n",
       "2  2015-02-24 11:15:48 -0800         Lets Play  Central Time (US & Canada)   \n",
       "3  2015-02-24 11:15:36 -0800               NaN  Pacific Time (US & Canada)   \n",
       "4  2015-02-24 11:14:45 -0800               NaN  Pacific Time (US & Canada)   \n",
       "5  2015-02-24 11:14:33 -0800               NaN  Pacific Time (US & Canada)   \n",
       "6  2015-02-24 11:13:57 -0800  San Francisco CA  Pacific Time (US & Canada)   \n",
       "7  2015-02-24 11:12:29 -0800       Los Angeles  Pacific Time (US & Canada)   \n",
       "8  2015-02-24 11:11:19 -0800         San Diego  Pacific Time (US & Canada)   \n",
       "9  2015-02-24 10:53:27 -0800       Los Angeles  Eastern Time (US & Canada)   \n",
       "\n",
       "                                          clean_text hashtags  \\\n",
       "0                                          what said       []   \n",
       "1     plus added commercials to the experience tacky       []   \n",
       "2          today must mean need to take another trip       []   \n",
       "3  really aggressive to blast obnoxious entertain...       []   \n",
       "4                  and really big bad thing about it       []   \n",
       "5  seriously would pay flight for seats that have...       []   \n",
       "6  yes nearly every time fly vx this ear worm won...       []   \n",
       "7  really missed prime opportunity for men withou...       []   \n",
       "8                                    well but now do       []   \n",
       "9  it was amazing and arrived an hour early too g...       []   \n",
       "\n",
       "                     handles  \n",
       "0  [VirginAmerica, dhepburn]  \n",
       "1            [VirginAmerica]  \n",
       "2            [VirginAmerica]  \n",
       "3            [VirginAmerica]  \n",
       "4            [VirginAmerica]  \n",
       "5            [VirginAmerica]  \n",
       "6            [VirginAmerica]  \n",
       "7            [VirginAmerica]  \n",
       "8            [virginamerica]  \n",
       "9            [VirginAmerica]  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['clean_text', 'airline', 'airline_sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text           0\n",
       "airline              0\n",
       "airline_sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Virgin America', 'United', 'Southwest', 'Delta', 'US Airways',\n",
       "       'American'], dtype=object)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"airline\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what said</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus added commercials to the experience tacky</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>today must mean need to take another trip</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really aggressive to blast obnoxious entertain...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and really big bad thing about it</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay flight for seats that have...</td>\n",
       "      <td>negative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes nearly every time fly vx this ear worm won...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>really missed prime opportunity for men withou...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>well but now do</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it was amazing and arrived an hour early too g...</td>\n",
       "      <td>positive</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text airline_sentiment  \\\n",
       "0                                          what said           neutral   \n",
       "1     plus added commercials to the experience tacky          positive   \n",
       "2          today must mean need to take another trip           neutral   \n",
       "3  really aggressive to blast obnoxious entertain...          negative   \n",
       "4                  and really big bad thing about it          negative   \n",
       "5  seriously would pay flight for seats that have...          negative   \n",
       "6  yes nearly every time fly vx this ear worm won...          positive   \n",
       "7  really missed prime opportunity for men withou...           neutral   \n",
       "8                                    well but now do          positive   \n",
       "9  it was amazing and arrived an hour early too g...          positive   \n",
       "\n",
       "   airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "0                 0              0                  0                   0   \n",
       "1                 0              0                  0                   0   \n",
       "2                 0              0                  0                   0   \n",
       "3                 0              0                  0                   0   \n",
       "4                 0              0                  0                   0   \n",
       "5                 0              0                  0                   0   \n",
       "6                 0              0                  0                   0   \n",
       "7                 0              0                  0                   0   \n",
       "8                 0              0                  0                   0   \n",
       "9                 0              0                  0                   0   \n",
       "\n",
       "   airline_United  airline_Virgin America  \n",
       "0               0                       1  \n",
       "1               0                       1  \n",
       "2               0                       1  \n",
       "3               0                       1  \n",
       "4               0                       1  \n",
       "5               0                       1  \n",
       "6               0                       1  \n",
       "7               0                       1  \n",
       "8               0                       1  \n",
       "9               0                       1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(\n",
    "    df, \n",
    "    prefix_sep='_', \n",
    "    dummy_na=False, \n",
    "    drop_first=False, \n",
    "    columns=['airline'], \n",
    "    dtype='int32'\n",
    ")\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>airline_sentiment</th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>what said</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plus added commercials to the experience tacky</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>today must mean need to take another trip</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>really aggressive to blast obnoxious entertain...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>and really big bad thing about it</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>seriously would pay flight for seats that have...</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>yes nearly every time fly vx this ear worm won...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>really missed prime opportunity for men withou...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>well but now do</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>it was amazing and arrived an hour early too g...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  airline_sentiment  \\\n",
       "0                                          what said                  0   \n",
       "1     plus added commercials to the experience tacky                  1   \n",
       "2          today must mean need to take another trip                  0   \n",
       "3  really aggressive to blast obnoxious entertain...                 -1   \n",
       "4                  and really big bad thing about it                 -1   \n",
       "5  seriously would pay flight for seats that have...                 -1   \n",
       "6  yes nearly every time fly vx this ear worm won...                  1   \n",
       "7  really missed prime opportunity for men withou...                  0   \n",
       "8                                    well but now do                  1   \n",
       "9  it was amazing and arrived an hour early too g...                  1   \n",
       "\n",
       "   airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "0                 0              0                  0                   0   \n",
       "1                 0              0                  0                   0   \n",
       "2                 0              0                  0                   0   \n",
       "3                 0              0                  0                   0   \n",
       "4                 0              0                  0                   0   \n",
       "5                 0              0                  0                   0   \n",
       "6                 0              0                  0                   0   \n",
       "7                 0              0                  0                   0   \n",
       "8                 0              0                  0                   0   \n",
       "9                 0              0                  0                   0   \n",
       "\n",
       "   airline_United  airline_Virgin America  \n",
       "0               0                       1  \n",
       "1               0                       1  \n",
       "2               0                       1  \n",
       "3               0                       1  \n",
       "4               0                       1  \n",
       "5               0                       1  \n",
       "6               0                       1  \n",
       "7               0                       1  \n",
       "8               0                       1  \n",
       "9               0                       1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['airline_sentiment'] = df['airline_sentiment'].apply(lambda x: -1 if x.lower() == 'negative' else (1 if x.lower() == 'positive' else 0))\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['airline_sentiment'], axis=1)  \n",
    "y = df['airline_sentiment']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10248, 7), (4392, 7), (10248,), (4392,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(clean_text                0\n",
       " airline_American          0\n",
       " airline_Delta             0\n",
       " airline_Southwest         0\n",
       " airline_US Airways        0\n",
       " airline_United            0\n",
       " airline_Virgin America    0\n",
       " dtype: int64,\n",
       " clean_text                0\n",
       " airline_American          0\n",
       " airline_Delta             0\n",
       " airline_Southwest         0\n",
       " airline_US Airways        0\n",
       " airline_United            0\n",
       " airline_Virgin America    0\n",
       " dtype: int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum(), X_test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12072</th>\n",
       "      <td>what happens when you combine top chef the bea...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7187</th>\n",
       "      <td>all good just have remind myself that if this ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12000</th>\n",
       "      <td>you cancelled flight my flight and there no wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3663</th>\n",
       "      <td>it was quite enjoyable except now stuck on the...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5249</th>\n",
       "      <td>standing in las vegas and our flight says on t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8855</th>\n",
       "      <td>but if customer service ment anything to you y...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12499</th>\n",
       "      <td>nothing you have done enough</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10227</th>\n",
       "      <td>working for me tight cx so delaying our flight...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14620</th>\n",
       "      <td>wait hrs for cs to call me back re why flt is ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7008</th>\n",
       "      <td>rt our on fleek</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              clean_text  airline_American  \\\n",
       "12072  what happens when you combine top chef the bea...                 1   \n",
       "7187   all good just have remind myself that if this ...                 0   \n",
       "12000  you cancelled flight my flight and there no wa...                 1   \n",
       "3663   it was quite enjoyable except now stuck on the...                 0   \n",
       "5249   standing in las vegas and our flight says on t...                 0   \n",
       "8855   but if customer service ment anything to you y...                 0   \n",
       "12499                       nothing you have done enough                 1   \n",
       "10227  working for me tight cx so delaying our flight...                 0   \n",
       "14620  wait hrs for cs to call me back re why flt is ...                 1   \n",
       "7008                                     rt our on fleek                 0   \n",
       "\n",
       "       airline_Delta  airline_Southwest  airline_US Airways  airline_United  \\\n",
       "12072              0                  0                   0               0   \n",
       "7187               1                  0                   0               0   \n",
       "12000              0                  0                   0               0   \n",
       "3663               0                  0                   0               1   \n",
       "5249               0                  1                   0               0   \n",
       "8855               1                  0                   0               0   \n",
       "12499              0                  0                   0               0   \n",
       "10227              0                  0                   1               0   \n",
       "14620              0                  0                   0               0   \n",
       "7008               1                  0                   0               0   \n",
       "\n",
       "       airline_Virgin America  \n",
       "12072                       0  \n",
       "7187                        0  \n",
       "12000                       0  \n",
       "3663                        0  \n",
       "5249                        0  \n",
       "8855                        0  \n",
       "12499                       0  \n",
       "10227                       0  \n",
       "14620                       0  \n",
       "7008                        0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa             0\n",
      "aadavantage    0\n",
      "aadv           0\n",
      "aadvantage     0\n",
      "aal            0\n",
      "              ..\n",
      "zero           0\n",
      "zone           0\n",
      "zoom           0\n",
      "zukes          0\n",
      "zurich         0\n",
      "Length: 8199, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>aal</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>aback</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>...</th>\n",
       "      <th>yyj</th>\n",
       "      <th>yyz</th>\n",
       "      <th>yyzua</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zcc</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 8199 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aadavantage  aadv  aadvantage  aal  aaron   ab  aback  abandon  \\\n",
       "0  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "1  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "2  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "3  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "4  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "5  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "6  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "7  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "8  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "9  0.0          0.0   0.0         0.0  0.0    0.0  0.0    0.0      0.0   \n",
       "\n",
       "   abandoned  ...  yyj  yyz  yyzua  zabsonre  zcc  zero  zone  zoom  zukes  \\\n",
       "0        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "1        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "2        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "3        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "4        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "5        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "6        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "7        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "8        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "9        0.0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0   \n",
       "\n",
       "   zurich  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  \n",
       "5     0.0  \n",
       "6     0.0  \n",
       "7     0.0  \n",
       "8     0.0  \n",
       "9     0.0  \n",
       "\n",
       "[10 rows x 8199 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "tfidf = vectorizer.fit_transform(X_train['clean_text'])\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "print(tfidf_df.isna().sum())\n",
    "\n",
    "tfidf_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10248, 7), (10248, 8199))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, tfidf_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_text            0\n",
       "airline_American      0\n",
       "airline_Delta         0\n",
       "airline_Southwest     0\n",
       "airline_US Airways    0\n",
       "                     ..\n",
       "zero                  0\n",
       "zone                  0\n",
       "zoom                  0\n",
       "zukes                 0\n",
       "zurich                0\n",
       "Length: 8206, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reset_index(drop=True) # need to do this, since X_train and tfidf_df have different indices\n",
    "\n",
    "X_train = pd.concat([X_train, tfidf_df], axis=1)\n",
    "\n",
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "      <th>aa</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>...</th>\n",
       "      <th>yyj</th>\n",
       "      <th>yyz</th>\n",
       "      <th>yyzua</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zcc</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 8205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "0                 1              0                  0                   0   \n",
       "1                 0              1                  0                   0   \n",
       "2                 1              0                  0                   0   \n",
       "3                 0              0                  0                   0   \n",
       "4                 0              0                  1                   0   \n",
       "5                 0              1                  0                   0   \n",
       "6                 1              0                  0                   0   \n",
       "7                 0              0                  0                   1   \n",
       "8                 1              0                  0                   0   \n",
       "9                 0              1                  0                   0   \n",
       "\n",
       "   airline_United  airline_Virgin America   aa  aadavantage  aadv  aadvantage  \\\n",
       "0               0                       0  0.0          0.0   0.0         0.0   \n",
       "1               0                       0  0.0          0.0   0.0         0.0   \n",
       "2               0                       0  0.0          0.0   0.0         0.0   \n",
       "3               1                       0  0.0          0.0   0.0         0.0   \n",
       "4               0                       0  0.0          0.0   0.0         0.0   \n",
       "5               0                       0  0.0          0.0   0.0         0.0   \n",
       "6               0                       0  0.0          0.0   0.0         0.0   \n",
       "7               0                       0  0.0          0.0   0.0         0.0   \n",
       "8               0                       0  0.0          0.0   0.0         0.0   \n",
       "9               0                       0  0.0          0.0   0.0         0.0   \n",
       "\n",
       "   ...  yyj  yyz  yyzua  zabsonre  zcc  zero  zone  zoom  zukes  zurich  \n",
       "0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "1  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "2  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "3  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "4  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "5  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "6  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "7  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "8  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "9  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "\n",
       "[10 rows x 8205 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.drop('clean_text',axis=1)\n",
    "\n",
    "X_train.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_American      0\n",
       "airline_Delta         0\n",
       "airline_Southwest     0\n",
       "airline_US Airways    0\n",
       "airline_United        0\n",
       "                     ..\n",
       "zero                  0\n",
       "zone                  0\n",
       "zoom                  0\n",
       "zukes                 0\n",
       "zurich                0\n",
       "Length: 8205, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>airline_American</th>\n",
       "      <th>airline_Delta</th>\n",
       "      <th>airline_Southwest</th>\n",
       "      <th>airline_US Airways</th>\n",
       "      <th>airline_United</th>\n",
       "      <th>airline_Virgin America</th>\n",
       "      <th>aa</th>\n",
       "      <th>aadavantage</th>\n",
       "      <th>aadv</th>\n",
       "      <th>aadvantage</th>\n",
       "      <th>...</th>\n",
       "      <th>yyj</th>\n",
       "      <th>yyz</th>\n",
       "      <th>yyzua</th>\n",
       "      <th>zabsonre</th>\n",
       "      <th>zcc</th>\n",
       "      <th>zero</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zukes</th>\n",
       "      <th>zurich</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 8205 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   airline_American  airline_Delta  airline_Southwest  airline_US Airways  \\\n",
       "0                 0              1                  0                   0   \n",
       "1                 0              1                  0                   0   \n",
       "2                 1              0                  0                   0   \n",
       "3                 0              1                  0                   0   \n",
       "4                 0              0                  0                   1   \n",
       "5                 0              0                  1                   0   \n",
       "6                 0              0                  0                   0   \n",
       "7                 0              0                  1                   0   \n",
       "8                 0              0                  0                   0   \n",
       "9                 0              0                  0                   1   \n",
       "\n",
       "   airline_United  airline_Virgin America   aa  aadavantage  aadv  aadvantage  \\\n",
       "0               0                       0  0.0          0.0   0.0         0.0   \n",
       "1               0                       0  0.0          0.0   0.0         0.0   \n",
       "2               0                       0  0.0          0.0   0.0         0.0   \n",
       "3               0                       0  0.0          0.0   0.0         0.0   \n",
       "4               0                       0  0.0          0.0   0.0         0.0   \n",
       "5               0                       0  0.0          0.0   0.0         0.0   \n",
       "6               1                       0  0.0          0.0   0.0         0.0   \n",
       "7               0                       0  0.0          0.0   0.0         0.0   \n",
       "8               1                       0  0.0          0.0   0.0         0.0   \n",
       "9               0                       0  0.0          0.0   0.0         0.0   \n",
       "\n",
       "   ...  yyj  yyz  yyzua  zabsonre  zcc  zero  zone  zoom  zukes  zurich  \n",
       "0  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "1  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "2  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "3  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "4  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "5  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "6  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "7  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "8  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "9  ...  0.0  0.0    0.0       0.0  0.0   0.0   0.0   0.0    0.0     0.0  \n",
       "\n",
       "[10 rows x 8205 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = vectorizer.transform(X_test['clean_text'])\n",
    "tfidf_df = pd.DataFrame(tfidf.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "X_test = X_test.reset_index(drop=True) # need to do this, since X_train and tfidf_df have different indices\n",
    "X_test = pd.concat([X_test, tfidf_df], axis=1)\n",
    "X_test = X_test.drop('clean_text',axis=1)\n",
    "\n",
    "X_test.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "airline_American      0\n",
       "airline_Delta         0\n",
       "airline_Southwest     0\n",
       "airline_US Airways    0\n",
       "airline_United        0\n",
       "                     ..\n",
       "zero                  0\n",
       "zone                  0\n",
       "zoom                  0\n",
       "zukes                 0\n",
       "zurich                0\n",
       "Length: 8205, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((4392, 8205), (10248, 8205))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Reduced Dimensions Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "User singular value decomposition (SVD) to create a reduced dimension dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(n_components=500, n_iter=10) #n_components is the number of topics, which should be less than the number of features, and number of rows in the matrix\n",
    "\n",
    "X_train_dim_reduct = svd.fit_transform(X_train)\n",
    "X_test_dim_reduct = svd.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10248, 500), (4392, 500))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dim_reduct.shape, X_test_dim_reduct.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fit RandomForrestClassifier using the dimension reduced training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 16min 43s\n",
      "Wall time: 55.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=2000, max_leaf_nodes=50, n_jobs=-1).fit(X_train_dim_reduct, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "y_train_pred = rf_clf.predict(X_train_dim_reduct)\n",
    "y_test_pred = rf_clf.predict(X_test_dim_reduct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6789\n",
      "Test accuracy: 0.6582\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2720,    8,    0],\n",
       "       [ 840,   97,    5],\n",
       "       [ 627,   21,   74]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_, colorbar=False)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_test_pred, display_labels=[-1,0,1], ax=ax, colorbar=False, cmap=plt.cm.Blues\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit RandomForrestClassifier using the original training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 3min 39s\n",
      "Wall time: 14.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "rf_clf = RandomForestClassifier(n_estimators=2000, max_leaf_nodes=50, n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "\n",
    "y_train_pred = rf_clf.predict(X_train)\n",
    "y_test_pred = rf_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.6612\n",
      "Test accuracy: 0.6498\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2726,    2,    0],\n",
       "       [ 899,   38,    5],\n",
       "       [ 629,    3,   90]], dtype=int64)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_, colorbar=False)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_test_pred, display_labels=[-1,0,1], ax=ax, colorbar=False, cmap=plt.cm.Blues\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit RandomForrestClassifier using the dimension reduced training data and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 20 candidates, totalling 60 fits\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 30, stop =70, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = [len(X_train.columns), len(X_train.columns)//2, len(X_train.columns)//5]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 50, num = 10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "# Use the random grid to search for best hyperparameters\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf_random = RandomizedSearchCV(\n",
    "    estimator = rf, \n",
    "    param_distributions = random_grid, \n",
    "    n_iter = 20, \n",
    "    cv = 3, \n",
    "    verbose=1, \n",
    "    random_state=42, \n",
    "    n_jobs = -1)\n",
    "\n",
    "_ = rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 70,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 1641,\n",
       " 'max_depth': None,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = rf_random.best_estimator_.predict(X_train)\n",
    "y_test_pred = rf_random.best_estimator_.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 0.9456\n",
      "Test accuracy: 0.7466\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train accuracy: {accuracy_score(y_train, y_train_pred):.4f}\")\n",
    "print(f\"Test accuracy: {accuracy_score(y_test, y_test_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2547,  121,   60],\n",
       "       [ 516,  360,   66],\n",
       "       [ 268,   82,  372]], dtype=int64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# display the confusion matrix\n",
    "cm = confusion_matrix(y_test, y_test_pred)\n",
    "#disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=le.classes_, colorbar=False)\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ConfusionMatrixDisplay.from_predictions(\n",
    "    y_test, y_test_pred, display_labels=[-1,0,1], ax=ax, colorbar=False, cmap=plt.cm.Blues\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2nd model on processed twetter data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Obtaining dependency information for tensorflow from https://files.pythonhosted.org/packages/9e/b8/ed5f794359d05cd0bffb894c6418da87b93016ee17b669d55c45d1bd5d5b/tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow-2.13.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting tensorflow-intel==2.13.0 (from tensorflow)\n",
      "  Obtaining dependency information for tensorflow-intel==2.13.0 from https://files.pythonhosted.org/packages/2f/2f/3c84f675931ce3bcbc7e23acbba1e5d7f05ce769adab48322de57a9f5928/tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for absl-py>=1.0.0 from https://files.pythonhosted.org/packages/01/e4/dc0a1dcc4e74e08d7abedab278c795eef54a224363bb18f5692f416d834f/absl_py-2.0.0-py3-none-any.whl.metadata\n",
      "  Downloading absl_py-2.0.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Collecting flatbuffers>=23.1.21 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for flatbuffers>=23.1.21 from https://files.pythonhosted.org/packages/6f/12/d5c79ee252793ffe845d58a913197bfa02ae9a0b5c9bc3dc4b58d477b9e7/flatbuffers-23.5.26-py2.py3-none-any.whl.metadata\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "     ---------------------------------------- 0.0/57.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 57.5/57.5 kB ? eta 0:00:00\n",
      "Collecting h5py>=2.9.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for h5py>=2.9.0 from https://files.pythonhosted.org/packages/d1/93/0f4cf5058095d749d464e4f770d2bf339930e5f3374331f0d2fa6ddfbf28/h5py-3.9.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading h5py-3.9.0-cp311-cp311-win_amd64.whl.metadata (2.5 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for libclang>=13.0.0 from https://files.pythonhosted.org/packages/02/8c/dc970bc00867fe290e8c8a7befa1635af716a9ebdfe3fb9dce0ca4b522ce/libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata\n",
      "  Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting numpy<=1.24.3,>=1.22 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "     ---------------------------------------- 0.0/14.8 MB ? eta -:--:--\n",
      "      --------------------------------------- 0.2/14.8 MB 7.6 MB/s eta 0:00:02\n",
      "     - -------------------------------------- 0.5/14.8 MB 6.7 MB/s eta 0:00:03\n",
      "     -- ------------------------------------- 0.8/14.8 MB 7.3 MB/s eta 0:00:02\n",
      "     --- ------------------------------------ 1.2/14.8 MB 7.4 MB/s eta 0:00:02\n",
      "     ---- ----------------------------------- 1.7/14.8 MB 9.0 MB/s eta 0:00:02\n",
      "     ------ --------------------------------- 2.3/14.8 MB 10.3 MB/s eta 0:00:02\n",
      "     ------- -------------------------------- 2.7/14.8 MB 10.2 MB/s eta 0:00:02\n",
      "     --------- ------------------------------ 3.4/14.8 MB 10.8 MB/s eta 0:00:02\n",
      "     ---------- ----------------------------- 3.8/14.8 MB 10.5 MB/s eta 0:00:02\n",
      "     ----------- ---------------------------- 4.4/14.8 MB 11.8 MB/s eta 0:00:01\n",
      "     ------------- -------------------------- 5.0/14.8 MB 11.7 MB/s eta 0:00:01\n",
      "     --------------- ------------------------ 5.7/14.8 MB 12.5 MB/s eta 0:00:01\n",
      "     ---------------- ----------------------- 6.2/14.8 MB 12.3 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 6.6/14.8 MB 12.5 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 7.3/14.8 MB 12.9 MB/s eta 0:00:01\n",
      "     --------------------- ------------------ 8.0/14.8 MB 13.0 MB/s eta 0:00:01\n",
      "     ---------------------- ----------------- 8.5/14.8 MB 13.3 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 9.1/14.8 MB 13.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------- 9.7/14.8 MB 13.5 MB/s eta 0:00:01\n",
      "     -------------------------- ------------ 10.2/14.8 MB 13.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ---------- 10.7/14.8 MB 14.2 MB/s eta 0:00:01\n",
      "     ----------------------------- --------- 11.3/14.8 MB 14.9 MB/s eta 0:00:01\n",
      "     ------------------------------- ------- 12.0/14.8 MB 15.2 MB/s eta 0:00:01\n",
      "     -------------------------------- ------ 12.5/14.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ---------------------------------- ---- 13.0/14.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- --- 13.5/14.8 MB 15.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- - 14.2/14.8 MB 16.0 MB/s eta 0:00:01\n",
      "     --------------------------------------  14.8/14.8 MB 15.6 MB/s eta 0:00:01\n",
      "     --------------------------------------  14.8/14.8 MB 15.6 MB/s eta 0:00:01\n",
      "     --------------------------------------- 14.8/14.8 MB 14.5 MB/s eta 0:00:00\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "     ---------------------------------------- 0.0/65.5 kB ? eta -:--:--\n",
      "     ---------------------------------------- 65.5/65.5 kB ? eta 0:00:00\n",
      "Requirement already satisfied: packaging in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (23.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 from https://files.pythonhosted.org/packages/5e/46/5b9674a33cbf690ffdd79ab1863767a66461cd06ea7aeb9f90e4e50be7a5/protobuf-4.24.3-cp310-abi3-win_amd64.whl.metadata\n",
      "  Downloading protobuf-4.24.3-cp310-abi3-win_amd64.whl.metadata (540 bytes)\n",
      "Requirement already satisfied: setuptools in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (68.0.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from tensorflow-intel==2.13.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
      "Collecting typing-extensions<4.6.0,>=3.6.6 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading typing_extensions-4.5.0-py3-none-any.whl (27 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading wrapt-1.15.0-cp311-cp311-win_amd64.whl (36 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for grpcio<2.0,>=1.24.3 from https://files.pythonhosted.org/packages/2c/98/6f45e1e42993c6b9e607b10a9a103e98e2e73d6fd430d4004adff216a98e/grpcio-1.58.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading grpcio-1.58.0-cp311-cp311-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting tensorboard<2.14,>=2.13 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorboard-2.13.0-py3-none-any.whl (5.6 MB)\n",
      "     ---------------------------------------- 0.0/5.6 MB ? eta -:--:--\n",
      "     ----- ---------------------------------- 0.8/5.6 MB 24.4 MB/s eta 0:00:01\n",
      "     -------- ------------------------------- 1.2/5.6 MB 20.0 MB/s eta 0:00:01\n",
      "     ------------ --------------------------- 1.8/5.6 MB 16.3 MB/s eta 0:00:01\n",
      "     ----------------- ---------------------- 2.5/5.6 MB 17.6 MB/s eta 0:00:01\n",
      "     ------------------- -------------------- 2.7/5.6 MB 17.5 MB/s eta 0:00:01\n",
      "     ------------------------ --------------- 3.4/5.6 MB 15.6 MB/s eta 0:00:01\n",
      "     ---------------------------- ----------- 3.9/5.6 MB 15.7 MB/s eta 0:00:01\n",
      "     -------------------------------- ------- 4.5/5.6 MB 15.3 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 5.2/5.6 MB 15.7 MB/s eta 0:00:01\n",
      "     ---------------------------------------  5.6/5.6 MB 15.5 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 5.6/5.6 MB 14.3 MB/s eta 0:00:00\n",
      "Collecting tensorflow-estimator<2.14,>=2.13.0 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for tensorflow-estimator<2.14,>=2.13.0 from https://files.pythonhosted.org/packages/72/5c/c318268d96791c6222ad7df1651bbd1b2409139afeb6f468c0f327177016/tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.14,>=2.13.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for keras<2.14,>=2.13.1 from https://files.pythonhosted.org/packages/2e/f3/19da7511b45e80216cbbd9467137b2d28919c58ba1ccb971435cb631e470/keras-2.13.1-py3-none-any.whl.metadata\n",
      "  Downloading keras-2.13.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.31.0-cp311-cp311-win_amd64.whl (1.5 MB)\n",
      "     ---------------------------------------- 0.0/1.5 MB ? eta -:--:--\n",
      "     --------------- ------------------------ 0.6/1.5 MB 18.8 MB/s eta 0:00:01\n",
      "     ------------------------------- -------- 1.2/1.5 MB 19.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.5/1.5 MB 15.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.13.0->tensorflow) (0.38.4)\n",
      "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for google-auth<3,>=1.6.3 from https://files.pythonhosted.org/packages/9d/44/5a992cb9d7bf8aaae73bc5adaf721ad08731c9d00c1c17999a8691404b0c/google_auth-2.23.0-py2.py3-none-any.whl.metadata\n",
      "  Downloading google_auth-2.23.0-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting google-auth-oauthlib<1.1,>=0.5 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading google_auth_oauthlib-1.0.0-py2.py3-none-any.whl (18 kB)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for markdown>=2.6.8 from https://files.pythonhosted.org/packages/1a/b5/228c1cdcfe138f1a8e01ab1b54284c8b83735476cb22b6ba251656ed13ad/Markdown-3.4.4-py3-none-any.whl.metadata\n",
      "  Downloading Markdown-3.4.4-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.31.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for tensorboard-data-server<0.8.0,>=0.7.0 from https://files.pythonhosted.org/packages/da/61/6e9ff8258422d287eec718872fb71e05324356722ab658c8afda25f51539/tensorboard_data_server-0.7.1-py3-none-any.whl.metadata\n",
      "  Downloading tensorboard_data_server-0.7.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for werkzeug>=1.0.1 from https://files.pythonhosted.org/packages/9b/59/a7c32e3d8d0e546a206e0552a2c04444544f15c1da4a01df8938d20c6ffc/werkzeug-2.3.7-py3-none-any.whl.metadata\n",
      "  Downloading werkzeug-2.3.7-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Obtaining dependency information for cachetools<6.0,>=2.0.0 from https://files.pythonhosted.org/packages/a9/c9/c8a7710f2cedcb1db9224fdd4d8307c9e48cbddc46c18b515fefc0f1abbe/cachetools-5.3.1-py3-none-any.whl.metadata\n",
      "  Downloading cachetools-5.3.1-py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "     ---------------------------------------- 0.0/181.3 kB ? eta -:--:--\n",
      "     ------------------------------------- 181.3/181.3 kB 11.4 MB/s eta 0:00:00\n",
      "Collecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Requirement already satisfied: urllib3<2.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.26.15)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2023.7.22)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow)\n",
      "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
      "     ---------------------------------------- 0.0/83.9 kB ? eta -:--:--\n",
      "     ---------------------------------------- 83.9/83.9 kB 4.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\rmura\\anaconda3\\envs\\text_analytics\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.14,>=2.13->tensorflow-intel==2.13.0->tensorflow) (3.2.2)\n",
      "Downloading tensorflow-2.13.0-cp311-cp311-win_amd64.whl (1.9 kB)\n",
      "Downloading tensorflow_intel-2.13.0-cp311-cp311-win_amd64.whl (276.6 MB)\n",
      "   ---------------------------------------- 0.0/276.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.7/276.6 MB 22.5 MB/s eta 0:00:13\n",
      "   ---------------------------------------- 1.4/276.6 MB 18.0 MB/s eta 0:00:16\n",
      "   ---------------------------------------- 2.1/276.6 MB 19.4 MB/s eta 0:00:15\n",
      "   ---------------------------------------- 2.8/276.6 MB 19.5 MB/s eta 0:00:15\n",
      "    --------------------------------------- 3.5/276.6 MB 18.7 MB/s eta 0:00:15\n",
      "    --------------------------------------- 4.2/276.6 MB 18.1 MB/s eta 0:00:16\n",
      "    --------------------------------------- 5.0/276.6 MB 18.8 MB/s eta 0:00:15\n",
      "    --------------------------------------- 5.6/276.6 MB 18.7 MB/s eta 0:00:15\n",
      "    --------------------------------------- 6.4/276.6 MB 19.4 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 6.9/276.6 MB 18.4 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 7.5/276.6 MB 18.5 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 8.3/276.6 MB 18.3 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 9.0/276.6 MB 18.5 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 9.7/276.6 MB 18.8 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 10.4/276.6 MB 19.3 MB/s eta 0:00:14\n",
      "   - -------------------------------------- 11.1/276.6 MB 18.7 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 11.8/276.6 MB 18.7 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 12.4/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 12.8/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   - -------------------------------------- 13.7/276.6 MB 17.7 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 14.4/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 15.2/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 16.0/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 16.6/276.6 MB 17.7 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 17.6/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 18.2/276.6 MB 17.7 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 19.2/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   -- ------------------------------------- 20.1/276.6 MB 18.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 21.1/276.6 MB 18.7 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 21.9/276.6 MB 18.2 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 22.7/276.6 MB 19.2 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 23.5/276.6 MB 18.7 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 24.0/276.6 MB 18.7 MB/s eta 0:00:14\n",
      "   --- ------------------------------------ 24.2/276.6 MB 17.3 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 24.7/276.6 MB 17.2 MB/s eta 0:00:15\n",
      "   --- ------------------------------------ 25.2/276.6 MB 16.4 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 25.8/276.6 MB 16.0 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 26.3/276.6 MB 16.0 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 26.7/276.6 MB 16.0 MB/s eta 0:00:16\n",
      "   --- ------------------------------------ 27.2/276.6 MB 15.2 MB/s eta 0:00:17\n",
      "   --- ------------------------------------ 27.5/276.6 MB 14.2 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 28.1/276.6 MB 13.9 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 28.8/276.6 MB 13.9 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 29.5/276.6 MB 13.9 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 30.1/276.6 MB 13.9 MB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 30.4/276.6 MB 13.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 30.9/276.6 MB 12.8 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 31.5/276.6 MB 13.1 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 32.2/276.6 MB 12.8 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 32.7/276.6 MB 12.8 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 33.3/276.6 MB 12.4 MB/s eta 0:00:20\n",
      "   ---- ----------------------------------- 33.9/276.6 MB 12.8 MB/s eta 0:00:19\n",
      "   ---- ----------------------------------- 34.5/276.6 MB 13.4 MB/s eta 0:00:19\n",
      "   ----- ---------------------------------- 35.2/276.6 MB 13.9 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 35.9/276.6 MB 13.9 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 36.7/276.6 MB 13.9 MB/s eta 0:00:18\n",
      "   ----- ---------------------------------- 37.3/276.6 MB 14.6 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 38.1/276.6 MB 14.9 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 38.5/276.6 MB 14.9 MB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 39.1/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 39.5/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 40.1/276.6 MB 14.9 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 40.7/276.6 MB 15.6 MB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 41.2/276.6 MB 15.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 41.8/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 42.6/276.6 MB 15.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 43.1/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 43.8/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 44.7/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 45.5/276.6 MB 15.2 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 46.2/276.6 MB 15.6 MB/s eta 0:00:15\n",
      "   ------ --------------------------------- 46.8/276.6 MB 14.9 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 47.1/276.6 MB 14.6 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 47.7/276.6 MB 14.5 MB/s eta 0:00:16\n",
      "   ------ --------------------------------- 48.3/276.6 MB 14.6 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 48.7/276.6 MB 14.2 MB/s eta 0:00:16\n",
      "   ------- -------------------------------- 49.2/276.6 MB 13.9 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 49.6/276.6 MB 13.9 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 50.1/276.6 MB 13.6 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 50.4/276.6 MB 13.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 51.0/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 51.5/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 52.0/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 52.7/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 53.1/276.6 MB 13.1 MB/s eta 0:00:18\n",
      "   ------- -------------------------------- 53.6/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 54.3/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   ------- -------------------------------- 54.9/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 55.4/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 56.2/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 56.8/276.6 MB 13.1 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 57.3/276.6 MB 13.4 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 58.0/276.6 MB 13.6 MB/s eta 0:00:17\n",
      "   -------- ------------------------------- 58.7/276.6 MB 14.2 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 59.4/276.6 MB 14.2 MB/s eta 0:00:16\n",
      "   -------- ------------------------------- 60.3/276.6 MB 14.9 MB/s eta 0:00:15\n",
      "   -------- ------------------------------- 60.7/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   -------- ------------------------------- 61.4/276.6 MB 15.2 MB/s eta 0:00:15\n",
      "   --------- ------------------------------ 62.3/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 63.0/276.6 MB 16.0 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 63.7/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 64.4/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 65.2/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 65.9/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 66.7/276.6 MB 15.6 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 67.3/276.6 MB 16.0 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 68.2/276.6 MB 16.0 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 68.6/276.6 MB 16.0 MB/s eta 0:00:14\n",
      "   --------- ------------------------------ 68.9/276.6 MB 14.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 69.4/276.6 MB 14.6 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 70.1/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 70.7/276.6 MB 14.5 MB/s eta 0:00:15\n",
      "   ---------- ----------------------------- 71.5/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 72.2/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 72.7/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 73.3/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 74.2/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 74.9/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ---------- ----------------------------- 75.6/276.6 MB 14.6 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 76.3/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 77.1/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 77.8/276.6 MB 15.2 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 78.6/276.6 MB 14.9 MB/s eta 0:00:14\n",
      "   ----------- ---------------------------- 79.4/276.6 MB 16.4 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 80.2/276.6 MB 16.4 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 80.7/276.6 MB 16.4 MB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 81.4/276.6 MB 15.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 82.1/276.6 MB 15.6 MB/s eta 0:00:13\n",
      "   ----------- ---------------------------- 82.7/276.6 MB 16.0 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 83.3/276.6 MB 15.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 83.9/276.6 MB 15.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 84.3/276.6 MB 15.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 85.0/276.6 MB 15.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 85.6/276.6 MB 15.2 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 85.9/276.6 MB 14.9 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 86.1/276.6 MB 14.9 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 87.0/276.6 MB 14.6 MB/s eta 0:00:14\n",
      "   ------------ --------------------------- 87.7/276.6 MB 14.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 88.3/276.6 MB 14.9 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 88.9/276.6 MB 14.6 MB/s eta 0:00:13\n",
      "   ------------ --------------------------- 89.6/276.6 MB 14.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 90.4/276.6 MB 14.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 90.8/276.6 MB 14.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 91.5/276.6 MB 14.6 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 92.1/276.6 MB 14.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 92.7/276.6 MB 14.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 93.4/276.6 MB 14.9 MB/s eta 0:00:13\n",
      "   ------------- -------------------------- 94.1/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 94.8/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 95.4/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 95.8/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   ------------- -------------------------- 96.5/276.6 MB 16.0 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 97.0/276.6 MB 16.4 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 97.7/276.6 MB 16.0 MB/s eta 0:00:12\n",
      "   -------------- ------------------------- 98.5/276.6 MB 16.4 MB/s eta 0:00:11\n",
      "   -------------- ------------------------- 99.2/276.6 MB 16.4 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 100.0/276.6 MB 16.4 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 100.9/276.6 MB 16.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 101.1/276.6 MB 16.8 MB/s eta 0:00:11\n",
      "   -------------- ------------------------ 101.6/276.6 MB 14.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 102.5/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 103.3/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 103.8/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 104.2/276.6 MB 15.6 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 105.0/276.6 MB 14.9 MB/s eta 0:00:12\n",
      "   -------------- ------------------------ 105.6/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 106.4/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 107.2/276.6 MB 15.2 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 107.7/276.6 MB 14.9 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 108.2/276.6 MB 14.9 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 108.7/276.6 MB 14.6 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 109.4/276.6 MB 14.6 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 110.2/276.6 MB 14.2 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 110.6/276.6 MB 13.9 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 111.2/276.6 MB 14.2 MB/s eta 0:00:12\n",
      "   --------------- ----------------------- 112.0/276.6 MB 15.2 MB/s eta 0:00:11\n",
      "   --------------- ----------------------- 112.8/276.6 MB 14.9 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 113.5/276.6 MB 14.6 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 113.8/276.6 MB 14.6 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 114.4/276.6 MB 13.9 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 114.9/276.6 MB 14.2 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 115.3/276.6 MB 13.9 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 115.8/276.6 MB 13.9 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 116.6/276.6 MB 13.9 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 117.5/276.6 MB 13.9 MB/s eta 0:00:12\n",
      "   ---------------- ---------------------- 118.5/276.6 MB 14.6 MB/s eta 0:00:11\n",
      "   ---------------- ---------------------- 119.6/276.6 MB 14.9 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 120.8/276.6 MB 16.0 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 121.1/276.6 MB 14.9 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 121.8/276.6 MB 15.2 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 122.6/276.6 MB 15.2 MB/s eta 0:00:11\n",
      "   ----------------- --------------------- 123.8/276.6 MB 16.4 MB/s eta 0:00:10\n",
      "   ----------------- --------------------- 125.0/276.6 MB 19.3 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 126.0/276.6 MB 20.5 MB/s eta 0:00:08\n",
      "   ----------------- --------------------- 126.9/276.6 MB 21.1 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 128.1/276.6 MB 21.1 MB/s eta 0:00:08\n",
      "   ------------------ -------------------- 129.1/276.6 MB 21.8 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 130.3/276.6 MB 21.1 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 131.5/276.6 MB 22.6 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 132.5/276.6 MB 23.4 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 133.9/276.6 MB 22.5 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 134.5/276.6 MB 22.6 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 135.3/276.6 MB 21.1 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 136.6/276.6 MB 21.1 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 137.7/276.6 MB 21.8 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 138.8/276.6 MB 22.6 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 139.9/276.6 MB 22.6 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 141.1/276.6 MB 22.6 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 142.1/276.6 MB 22.5 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 143.1/276.6 MB 21.9 MB/s eta 0:00:07\n",
      "   -------------------- ------------------ 144.5/276.6 MB 23.4 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 145.2/276.6 MB 24.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 146.2/276.6 MB 24.3 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 147.5/276.6 MB 24.2 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 148.3/276.6 MB 23.4 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 149.8/276.6 MB 24.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 150.7/276.6 MB 25.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 152.0/276.6 MB 25.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 153.0/276.6 MB 26.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 153.5/276.6 MB 24.2 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 154.5/276.6 MB 23.4 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 155.5/276.6 MB 24.2 MB/s eta 0:00:05\n",
      "   --------------------- ----------------- 156.0/276.6 MB 22.6 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 157.3/276.6 MB 23.4 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 158.6/276.6 MB 23.4 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 159.4/276.6 MB 21.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 159.7/276.6 MB 21.8 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 160.6/276.6 MB 21.1 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 162.2/276.6 MB 21.8 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 163.4/276.6 MB 21.9 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 164.8/276.6 MB 24.2 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 165.2/276.6 MB 21.8 MB/s eta 0:00:06\n",
      "   ----------------------- --------------- 166.2/276.6 MB 22.6 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 167.5/276.6 MB 22.6 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 168.3/276.6 MB 22.6 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 168.6/276.6 MB 21.9 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 169.8/276.6 MB 21.8 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 170.6/276.6 MB 22.6 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 171.9/276.6 MB 23.4 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 173.0/276.6 MB 22.5 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 173.4/276.6 MB 21.1 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 173.6/276.6 MB 19.8 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 173.8/276.6 MB 19.3 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 174.2/276.6 MB 16.8 MB/s eta 0:00:07\n",
      "   ------------------------ -------------- 175.5/276.6 MB 18.2 MB/s eta 0:00:06\n",
      "   ------------------------ -------------- 176.6/276.6 MB 18.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 177.6/276.6 MB 17.7 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 178.7/276.6 MB 18.2 MB/s eta 0:00:06\n",
      "   ------------------------- ------------- 180.3/276.6 MB 19.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 181.7/276.6 MB 19.8 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 183.2/276.6 MB 19.9 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 184.4/276.6 MB 27.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 185.4/276.6 MB 27.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 186.7/276.6 MB 27.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 188.0/276.6 MB 27.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 189.1/276.6 MB 27.3 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 190.4/276.6 MB 26.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 191.6/276.6 MB 26.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 192.7/276.6 MB 26.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 193.7/276.6 MB 25.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 194.4/276.6 MB 25.1 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 195.1/276.6 MB 25.2 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 195.5/276.6 MB 23.4 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 196.3/276.6 MB 22.6 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 196.4/276.6 MB 20.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 196.8/276.6 MB 20.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 196.8/276.6 MB 20.5 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 196.9/276.6 MB 17.7 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 197.3/276.6 MB 16.4 MB/s eta 0:00:05\n",
      "   --------------------------- ----------- 197.9/276.6 MB 15.6 MB/s eta 0:00:06\n",
      "   --------------------------- ----------- 198.2/276.6 MB 14.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 198.8/276.6 MB 14.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 199.5/276.6 MB 14.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 200.3/276.6 MB 14.6 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 200.9/276.6 MB 14.2 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 201.9/276.6 MB 13.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 202.8/276.6 MB 13.9 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 204.1/276.6 MB 14.2 MB/s eta 0:00:06\n",
      "   ---------------------------- ---------- 204.7/276.6 MB 13.9 MB/s eta 0:00:06\n",
      "   ----------------------------- --------- 205.7/276.6 MB 14.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 206.4/276.6 MB 14.6 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 207.5/276.6 MB 18.7 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 208.6/276.6 MB 21.1 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 208.8/276.6 MB 21.1 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 209.2/276.6 MB 19.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 209.6/276.6 MB 18.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 209.9/276.6 MB 17.3 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 210.2/276.6 MB 17.2 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 210.9/276.6 MB 16.4 MB/s eta 0:00:05\n",
      "   ----------------------------- --------- 211.5/276.6 MB 16.4 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 212.1/276.6 MB 16.0 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 212.9/276.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 214.0/276.6 MB 15.6 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 214.7/276.6 MB 15.2 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 215.2/276.6 MB 14.9 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 215.9/276.6 MB 14.6 MB/s eta 0:00:05\n",
      "   ------------------------------ -------- 216.8/276.6 MB 15.2 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 217.7/276.6 MB 14.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 218.7/276.6 MB 14.9 MB/s eta 0:00:04\n",
      "   ------------------------------ -------- 219.4/276.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 220.1/276.6 MB 17.7 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 220.1/276.6 MB 16.4 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 220.7/276.6 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 221.2/276.6 MB 16.8 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 221.5/276.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 222.1/276.6 MB 16.0 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 222.5/276.6 MB 15.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 222.9/276.6 MB 14.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 223.2/276.6 MB 14.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 223.7/276.6 MB 13.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 224.1/276.6 MB 13.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 224.6/276.6 MB 13.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 225.2/276.6 MB 13.6 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 226.0/276.6 MB 13.9 MB/s eta 0:00:04\n",
      "   ------------------------------- ------- 226.3/276.6 MB 13.4 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 227.0/276.6 MB 13.4 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 227.8/276.6 MB 12.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 228.4/276.6 MB 12.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 229.0/276.6 MB 12.8 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 229.8/276.6 MB 12.9 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 230.7/276.6 MB 13.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 231.2/276.6 MB 13.6 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 232.0/276.6 MB 14.2 MB/s eta 0:00:04\n",
      "   -------------------------------- ------ 232.8/276.6 MB 15.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 233.6/276.6 MB 15.2 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 234.5/276.6 MB 16.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 235.3/276.6 MB 16.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 236.1/276.6 MB 16.0 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 236.8/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 237.7/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 238.2/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 238.9/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 239.6/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   --------------------------------- ----- 240.5/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 241.3/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 242.2/276.6 MB 16.8 MB/s eta 0:00:03\n",
      "   ---------------------------------- ---- 243.3/276.6 MB 17.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 244.3/276.6 MB 17.7 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 245.2/276.6 MB 18.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 246.5/276.6 MB 19.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 247.1/276.6 MB 18.2 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 248.0/276.6 MB 19.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 249.0/276.6 MB 19.8 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 250.2/276.6 MB 21.1 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 251.2/276.6 MB 20.5 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 252.6/276.6 MB 23.4 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 253.9/276.6 MB 22.6 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 254.9/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 256.1/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 257.2/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 258.3/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 259.1/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 260.1/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 261.3/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 262.2/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 263.1/276.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 264.3/276.6 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 265.5/276.6 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 266.7/276.6 MB 21.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 268.0/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 268.9/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  270.1/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  271.1/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  271.1/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  272.0/276.6 MB 21.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  273.0/276.6 MB 21.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  274.1/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  275.6/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.5/276.6 MB 23.4 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------  276.6/276.6 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------------- 276.6/276.6 MB 11.9 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.0.0-py3-none-any.whl (130 kB)\n",
      "   ---------------------------------------- 0.0/130.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 130.2/130.2 kB ? eta 0:00:00\n",
      "Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Downloading grpcio-1.58.0-cp311-cp311-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 1.0/4.3 MB 20.5 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 2.0/4.3 MB 21.0 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.0/4.3 MB 21.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  4.3/4.3 MB 22.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 21.1 MB/s eta 0:00:00\n",
      "Downloading h5py-3.9.0-cp311-cp311-win_amd64.whl (2.7 MB)\n",
      "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 1.3/2.7 MB 42.6 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 2.0/2.7 MB 25.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.7/2.7 MB 24.0 MB/s eta 0:00:00\n",
      "Downloading keras-2.13.1-py3-none-any.whl (1.7 MB)\n",
      "   ---------------------------------------- 0.0/1.7 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 0.3/1.7 MB ? eta -:--:--\n",
      "   ---------------------------- ----------- 1.2/1.7 MB 15.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.7/1.7 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading libclang-16.0.6-py2.py3-none-win_amd64.whl (24.4 MB)\n",
      "   ---------------------------------------- 0.0/24.4 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.4/24.4 MB 8.9 MB/s eta 0:00:03\n",
      "   -- ------------------------------------- 1.8/24.4 MB 18.6 MB/s eta 0:00:02\n",
      "   ---- ----------------------------------- 2.6/24.4 MB 18.4 MB/s eta 0:00:02\n",
      "   ----- ---------------------------------- 3.2/24.4 MB 20.2 MB/s eta 0:00:02\n",
      "   ------ --------------------------------- 4.1/24.4 MB 18.7 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 5.3/24.4 MB 19.8 MB/s eta 0:00:01\n",
      "   ---------- ----------------------------- 6.3/24.4 MB 20.2 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 7.4/24.4 MB 20.6 MB/s eta 0:00:01\n",
      "   ------------ --------------------------- 7.9/24.4 MB 20.3 MB/s eta 0:00:01\n",
      "   ------------- -------------------------- 8.3/24.4 MB 18.4 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 9.4/24.4 MB 18.2 MB/s eta 0:00:01\n",
      "   ----------------- ---------------------- 10.4/24.4 MB 19.3 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 11.3/24.4 MB 19.8 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 12.2/24.4 MB 19.3 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 13.3/24.4 MB 19.3 MB/s eta 0:00:01\n",
      "   ----------------------- ---------------- 14.3/24.4 MB 18.7 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 15.3/24.4 MB 19.8 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 16.7/24.4 MB 19.8 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 17.8/24.4 MB 19.9 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 18.7/24.4 MB 21.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 20.1/24.4 MB 22.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 20.7/24.4 MB 22.6 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 21.2/24.4 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 22.4/24.4 MB 21.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 23.1/24.4 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  23.9/24.4 MB 20.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.1/24.4 MB 19.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  24.4/24.4 MB 18.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 24.4/24.4 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading protobuf-4.24.3-cp310-abi3-win_amd64.whl (430 kB)\n",
      "   ---------------------------------------- 0.0/430.5 kB ? eta -:--:--\n",
      "   --------------------------------------- 430.5/430.5 kB 13.6 MB/s eta 0:00:00\n",
      "Downloading tensorflow_estimator-2.13.0-py2.py3-none-any.whl (440 kB)\n",
      "   ---------------------------------------- 0.0/440.8 kB ? eta -:--:--\n",
      "   --------------------------------------- 440.8/440.8 kB 28.7 MB/s eta 0:00:00\n",
      "Downloading google_auth-2.23.0-py2.py3-none-any.whl (181 kB)\n",
      "   ---------------------------------------- 0.0/181.4 kB ? eta -:--:--\n",
      "   --------------------------------------- 181.4/181.4 kB 10.7 MB/s eta 0:00:00\n",
      "Downloading Markdown-3.4.4-py3-none-any.whl (94 kB)\n",
      "   ---------------------------------------- 0.0/94.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 94.2/94.2 kB ? eta 0:00:00\n",
      "Downloading tensorboard_data_server-0.7.1-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-2.3.7-py3-none-any.whl (242 kB)\n",
      "   ---------------------------------------- 0.0/242.2 kB ? eta -:--:--\n",
      "   ---------------------------------------- 242.2/242.2 kB ? eta 0:00:00\n",
      "Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, typing-extensions, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, protobuf, numpy, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, pyasn1-modules, opt-einsum, h5py, google-auth, google-auth-oauthlib, tensorboard, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.7.1\n",
      "    Uninstalling typing_extensions-4.7.1:\n",
      "      Successfully uninstalled typing_extensions-4.7.1\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.25.2\n",
      "    Uninstalling numpy-1.25.2:\n",
      "      Successfully uninstalled numpy-1.25.2\n",
      "Successfully installed absl-py-2.0.0 astunparse-1.6.3 cachetools-5.3.1 flatbuffers-23.5.26 gast-0.4.0 google-auth-2.23.0 google-auth-oauthlib-1.0.0 google-pasta-0.2.0 grpcio-1.58.0 h5py-3.9.0 keras-2.13.1 libclang-16.0.6 markdown-3.4.4 numpy-1.24.3 opt-einsum-3.3.0 protobuf-4.24.3 pyasn1-0.5.0 pyasn1-modules-0.3.0 rsa-4.9 tensorboard-2.13.0 tensorboard-data-server-0.7.1 tensorflow-2.13.0 tensorflow-estimator-2.13.0 tensorflow-intel-2.13.0 tensorflow-io-gcs-filesystem-0.31.0 termcolor-2.3.0 typing-extensions-4.5.0 werkzeug-2.3.7 wrapt-1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "pydantic 2.3.0 requires typing-extensions>=4.6.1, but you have typing-extensions 4.5.0 which is incompatible.\n",
      "pydantic-core 2.6.3 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "# Add convolutional layer. Learn 16 filters using a 3x3 kernel\n",
    "model.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu', input_shape=(32,32,3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.15))\n",
    "\n",
    "# Add convolutional layer. Learn 32 filters using a 3x3 kernel\n",
    "model.add(Conv2D(filters=64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(rate=0.1))\n",
    "\n",
    "# Flatten to a 1d array for feeding into our dense layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add a dense layer with 128 neurons\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(rate=0.5))\n",
    "\n",
    "# Add the final prediction later with 10 neurons, one for each class\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
