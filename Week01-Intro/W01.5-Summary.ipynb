{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "**Week01, Section 05**\n",
    "\n",
    "ISM6564 Fall 2023\n",
    "\n",
    "&copy; 2023 Dr. Tim Smith\n",
    "\n",
    "-----\n",
    "\n",
    "## Encoding/Decoding Text\n",
    "* Comprehend how computers perceive data: binary, hexadecimal, bytes, little endian, and big endian\n",
    "* Understand the notion of encoding and its significance\n",
    "* Distinguish between a byte and a character\n",
    "* Grasp the concept of character/file encoding and character mapping.\n",
    "* Familiarize with the most common character encodings\n",
    "* Differentiate between ASCII, Unicode (UTF-8, UTF-16, UTF-32), and ISO-8959-x codepages\n",
    "* Comprehend the difference between Codepage and UTF encoding\n",
    "\n",
    "## Codecs and Python\n",
    "* Utilize Python programming language for reading and writing text files with various encodings\n",
    "* Implement encoding/decoding in Python\n",
    "* Know how to specify the encoding during file reading and writing\n",
    "* Address encoding errors effectively\n",
    "* Identify the encoding of a file\n",
    "\n",
    "## File I/O in Python\n",
    "* Open a file for reading as text\n",
    "* Open a file for writing as binary\n",
    "* Open a file for reading and writing as text\n",
    "* Open a file for reading and writing as binary\n",
    "* Seeking in a file\n",
    "* Reading a file line by line\n",
    "* Reading a file character by character\n",
    "* Reading a file all at once\n",
    "\n",
    "## Exploratory Text Analysis\n",
    "- Introduce and Review important Concepts\n",
    "  - Corpus, a collection of documents (in the example below, a single document)\n",
    "  - Tokenization, the process of breaking up a document into individual words\n",
    "  - Lemizaton, the process of reducing words to their root form\n",
    "  - Stopwords, words that are not useful for analysis\n",
    "  - n-Grams, a sequence of n words\n",
    "  - Wordcloud, a visualization of the most common words in a corpus\n",
    "  - Sentiment Analysis, the process of determining the sentiment of a document (positive, negative, neutral)\n",
    "- How to conduct exploratory textual data analysis\n",
    "  - Load text\n",
    "  - Tokenize\n",
    "  - Filter \n",
    "    - remove stopwords\n",
    "    - remove certain patterns (i.e. non-alphabetic characters)\n",
    "  - Lemmatize Words\n",
    "    - Not always necessary - depends on goals\n",
    "  - Analysis\n",
    "    - Word Frequencies\n",
    "      - calculate word frequencies\n",
    "      - chart word frequencies\n",
    "    - Wordcloud\n",
    "      - generate wordcloud from word frequencies\n",
    "      - generate wordcloud from text\n",
    "        - n-grams\n",
    "      - adjust wordcloud appearance\n",
    "        - masking (shape)\n",
    "    - Sentiment\n",
    "      - positive, neutral, negative and composite\n",
    "      - chart sentiment\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
