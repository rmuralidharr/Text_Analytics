{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from api_key import my_key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "openai.api_key=my_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"Can you explain \\nabout this LinkedIn profile https://www.linkedin.com/in/murali-mdr/ he is suit for AI ML DL jobs\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"I apologize, but I am an AI language model and I cannot access or analyze specific LinkedIn profiles. However, I can provide you some general information about how to determine if someone is suitable for AI, ML, or DL jobs based on their LinkedIn profile.\\n\\n1. Job Experience: Look at the candidate's previous job roles and responsibilities. If they have relevant experience working in the field of AI (Artificial Intelligence), ML (Machine Learning), or DL (Deep Learning), it can be an indicator of their suitability for AI-related positions.\\n\\n2. Skills and Endorsements: Check for skills listed on their profile. Look for AI-related skills such as machine learning, deep learning, natural language processing, computer vision, data analysis, etc. Additionally, endorsements from others can also give you an idea of the candidate's proficiency in these areas.\\n\\n3. Education: Consider their educational background. A relevant degree in computer science, data science, or a related field can be a positive sign. Advanced degrees or specialized certifications in AI, ML, or DL can also demonstrate a higher level of expertise.\\n\\n4. Projects and Publications: Look for any AI-related projects or publications the candidate has worked on. This can show their practical experience and familiarity with industry trends and research.\\n\\n5. Recommendations:\"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"user\",\n",
    "      \"content\": \"looking to profile and tell me \"\n",
    "    },\n",
    "    {\n",
    "      \"role\": \"assistant\",\n",
    "      \"content\": \"I apologize for the confusion, but as an AI language model, I cannot access external links or profiles, including the one you provided. Therefore, I am unable to directly analyze or evaluate the profile you mentioned.\"\n",
    "    }\n",
    "  ],\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_values(['chatcmpl-875VqNX8PMVYpYUg3VzYPjvHsFYVZ', 'chat.completion', 1696700178, 'gpt-3.5-turbo-0613', [<OpenAIObject at 0x1fe1cf37b30> JSON: {\n",
       "  \"finish_reason\": \"stop\",\n",
       "  \"index\": 0,\n",
       "  \"message\": {\n",
       "    \"content\": \"I apologize for the confusion, but as an AI language model, I cannot access external links or profiles. Therefore, I am unable to directly analyze or evaluate the specific LinkedIn profile you mentioned. My purpose is to provide general information and assistance based on the questions and prompts you provide.\",\n",
       "    \"role\": \"assistant\"\n",
       "  }\n",
       "}], <OpenAIObject at 0x1fe1e9f44d0> JSON: {\n",
       "  \"completion_tokens\": 56,\n",
       "  \"prompt_tokens\": 352,\n",
       "  \"total_tokens\": 408\n",
       "}])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['id', 'object', 'created', 'model', 'choices', 'usage'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "send",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\rmura\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\openai\\openai_object.py:59\u001b[0m, in \u001b[0;36mOpenAIObject.__getattr__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     58\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m[k]\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'send'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\rmura\\Murali\\Text Analytics\\week7\\samplerunChatgpt.ipynb Cell 6\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/rmura/Murali/Text%20Analytics/week7/samplerunChatgpt.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m response\u001b[39m.\u001b[39;49msend()\n",
      "File \u001b[1;32mc:\\Users\\rmura\\anaconda3\\envs\\text_analytics\\Lib\\site-packages\\openai\\openai_object.py:61\u001b[0m, in \u001b[0;36mOpenAIObject.__getattr__\u001b[1;34m(self, k)\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m[k]\n\u001b[0;32m     60\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m---> 61\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m*\u001b[39merr\u001b[39m.\u001b[39margs)\n",
      "\u001b[1;31mAttributeError\u001b[0m: send"
     ]
    }
   ],
   "source": [
    "response."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "text_analytics",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
